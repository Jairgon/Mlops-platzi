{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo y registro de modelos con MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import scipy\n",
    "import os\n",
    "from datetime import datetime\n",
    "import xgboost\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mlflow\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri()\n",
    "mlflow.set_experiment()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filename:str):\n",
    "    \"\"\"this functions loads a pickle file\n",
    "    Args:\n",
    "        filename (str): path to the pickle file\n",
    "    Returns:\n",
    "        object: the object contained in the pickle file\"\"\"\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_pickle(os.path.join(\"data/data_processed\", \"train.pkl\"))\n",
    "X_val, y_val = load_pickle(os.path.join(\"data/data_processed\", \"valid.pkl\"))\n",
    "X_test, y_test = load_pickle(os.path.join(\"data/data_processed\", \"test.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lasso_regression(X_train: scipy.sparse._csr.csr_matrix, y_train: scipy.sparse._csr.csr_matrix, \n",
    "                         X_val: scipy.sparse._csr.csr_matrix, y_val: scipy.sparse._csr.csr_matrix, \n",
    "                         X_test: scipy.sparse._csr.csr_matrix, y_test: scipy.sparse._csr.csr_matrix):\n",
    "    \"\"\"\n",
    "    \n",
    "    Perform Lasso regression using the provided training, validation, and test data, \n",
    "    remember we are using as a backend store uri mlflow.db\n",
    "    copy this in the terminal mlflow ui --backend-store-uri sqlite:///mlflow.db\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training feature data\n",
    "    - y_train: Training target data\n",
    "    - X_val: Validation feature data\n",
    "    - y_val: Validation target data\n",
    "    - X_test: Test feature data\n",
    "    - y_test: Test target data\n",
    "\n",
    "    Returns:\n",
    "    - Trained Lasso regression model\n",
    "    \"\"\"\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_lasso_regression(X_train, y_train, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validación de hiperparametros con optimización del rmse con Hyperot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)\n",
    "test = xgb.DMatrix(X_test, label=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params: dict):\n",
    "    \"\"\"\n",
    "    Optimize an XGBoost model using hyperopt and MLflow.\n",
    "    Parameters:\n",
    "    - params (dict): Dictionary containing XGBoost hyperparameters.\n",
    "    Returns:\n",
    "    - dict: Dictionary containing loss and status for the hyperparameter optimization.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:linear',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a la UI y simulemos que algún cientifico de datos o miembro del equipo decide registrar ciertos modelos en \"staging\", y más adelante nosotros como ingenieros de ML tomamos la decisión de cual modelo registrar para producción bajo las métricas de performance obtenidas y las pruebas. Es muy importante hacer las pruebas de validación antes de considerar un modelo en producción. Entre ellas se encuentran las siguientes:\n",
    "\n",
    "#### 1. Pruebas de funcionalidad:\n",
    "\n",
    "* Funcionalidad del Modelo: Asegurarse de que el modelo funcione correctamente en el entorno de producción con los datos reales (Se puede simular con cierta parte de la data o toda idealmente).\n",
    "* Integración del Modelo: Verificar que el modelo integrado en la infraestructura de producción responda y se comunique adecuadamente con otros componentes del sistema (partes del Pipeline).\n",
    "\n",
    "####  2. Pruebas de rendimiento:\n",
    "* Rendimiento del Modelo: Evaluar el rendimiento del modelo en términos de velocidad de inferencia, uso de recursos (CPU, memoria), y latencia para garantizar que cumple con los requisitos de producción. (El tiempo es un factor muy importante en la generación de soluciones de negocio)\n",
    "* Escala y Carga: Probar el modelo bajo cargas esperadas para asegurar que el sistema es escalable y puede manejar la demanda prevista. (Orar para que el Kernel no muera con la carga, de lo contrario mirar formas de optimizar el código, hacer carga de datos por chuncks, paralelizar procesos, etc)\n",
    "\n",
    "#### 3. Pruebas de robustez:\n",
    "* Robustez de estrés: Evaluar el comportamiento del modelo en condiciones adversas, como datos de entrada no esperados, valores faltantes, valores atípicos, etc. (Esto es muy importante, ya que en la vida real los datos no son perfectos, y es muy probable que el modelo se caiga si no se tiene en cuenta este factor por lo que generar pruebas unitarias para este tipo de casos es muy importante). \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions from MLflow artifacts\n",
    "\n",
    "Predict on Pandas DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = \n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info from the loaded model\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model registry and state transitions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://pbs.twimg.com/media/EoOBoWyWEAAA8In.jpg\" width=\"400\" style=\"display: block; margin: auto;\">\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tener en cuenta el tiempo de ejecución.\n",
    "\n",
    "* Métricas obtenidas.\n",
    "\n",
    "* Tamaño del modelo.\n",
    "\n",
    "* Las pruebas que anteriormente mencionamos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extrae los IDs únicos de los experimentos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promote a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"a90d6cc190014a21ba5a0dc4de13f94e\"\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "mlflow.register_model(model_uri, \"regressor_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando vayas a cambiar el staging de un modelo a otro estado, podemos también añadir descripciones: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a register model\n",
    "\n",
    "De esta forma se deben hacer las pruebas con el pipeline de producción para asegurar que el modelo se comporta como se espera. Además de validar la infraestructura y las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OJO: Es importante que recuerdes los formatos permitidos por mlflow load_model, como dataframes, numpy arrays, etc.\n",
    "def testint_model_from_mlflow(model_name: str, stage:str, X_test: xgboost.core.DMatrix, Y_test: np.ndarray):\n",
    "    \"\"\"this function tests a model from mlflow\n",
    "    Args:\n",
    "        model_name (str): name of the model\n",
    "        stage (str): stage of the model\n",
    "        X_test (scipy.sparse._csr.csr_matrix): test data\n",
    "        Y_test (scipy.sparse._csr.csr_matrix): test target\n",
    "    Returns:\n",
    "        float: rmse of the model\n",
    "    \n",
    "    \"\"\"\n",
    "    model_uri = f\"models:/{model_name}/{stage}\"\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "    return {\"rmse\": rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "testint_model_from_mlflow(model_name= \"regressor_model\", stage=\"Production\", X_test=test, Y_test=test.get_label())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ventajas de MLflow:\n",
    "\n",
    "* Gestión de Ciclo de Vida: Facilita el seguimiento de experimentos, versionado de modelos y reproducción de resultados.\n",
    "* Interoperabilidad: Es compatible con múltiples frameworks de aprendizaje automático y se integra fácilmente en flujos de trabajo existentes.\n",
    "* Abierto y Modular: Ofrece una arquitectura modular que permite la flexibilidad y personalización.\n",
    "* Trazabilidad y Reproducibilidad: Registra métricas, parámetros y artefactos para reproducir modelos y resultados.\n",
    "* Comunidad Activa: Amplia comunidad de usuarios y contribuciones continuas.\n",
    "\n",
    "\n",
    "#### Desventajas de MLflow:\n",
    "* Complejidad para Grandes Volúmenes de Datos: Puede enfrentar dificultades al manejar grandes volúmenes de datos o flujos de trabajo muy complejos.\n",
    "* Curva de Aprendizaje: Requiere tiempo para familiarizarse con todas sus funcionalidades y componentes.\n",
    "Limitaciones en Algunas Funcionalidades: Algunas funcionalidades pueden no ser tan avanzadas o flexibles como en otras herramientas especializadas.\n",
    "\n",
    "\n",
    "### Alternativas a MLflow:\n",
    "* TensorBoard: Enfoque específico para TensorFlow, útil para visualizar gráficamente métricas, grafos de modelos y más.\n",
    "* DVC (Data Version Control): Se enfoca en versionado de datos y modelos, y gestión de experimentos.\n",
    "* Comet.ml: Ofrece seguimiento de experimentos, colaboración y visualización de manera similar a MLflow.\n",
    "* Weights & Biases: Ofrece seguimiento de experimentos, colaboración y visualización de manera similar a MLflow.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones\n",
    "\n",
    "* Podemos trackear metadata\n",
    "\n",
    "* Registrar modelos\n",
    "\n",
    "* Obtener los requirimientos del ambiente de desarrollo donde fue entrenado los modelos\n",
    "\n",
    "* Podemos hacer un seguimiento de los modelos y compararlos de forma fácil y amigable con la interfaz de MLflow y en código\n",
    "\n",
    "* Hacer transiciones de estados de los modelos\n",
    "\n",
    "* Añadir anotaciones o descripciones \n",
    "\n",
    "So, ya sabes incluír el registro de modelos en nuestro pipeline de ML, ahora vamos a aprender de workflows y tasks. ¡Te espero en la próxima clase! :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-curso-py3.9",
   "language": "python",
   "name": "mlops-curso-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
